{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Embedding, Input, Bidirectional, LSTM, concatenate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "!python -m spacy download en_core_web_md"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting en-core-web-md==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.1.0/en_core_web_md-3.1.0-py3-none-any.whl (45.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 45.4 MB 12.7 MB/s eta 0:00:01   |███▍                            | 4.8 MB 2.8 MB/s eta 0:00:15��████████        | 34.1 MB 65.7 MB/s eta 0:00:01██████████████▋       | 34.9 MB 65.7 MB/s eta 0:00:01███████████████       | 35.4 MB 65.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from en-core-web-md==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: jinja2 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.26.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (21.0)\n",
      "Requirement already satisfied: setuptools in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (57.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.19.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (4.62.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.2)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (8.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/benclowe/.local/share/virtualenvs/Kickstarter_copy-Sf0oGEBf/lib/python3.9/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load first file\n",
    "df = pd.read_csv('Kickstarter.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Loop through 8 files and concat to original DF\n",
    "for i in range(8):\n",
    "  df_ = pd.read_csv(f'Kickstarter00{i+1}.csv')\n",
    "  df = pd.concat([df, df_])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def clean_data(df):\n",
    "\n",
    "  # Removing duplicate entries then set 'id' as index\n",
    "  df.drop_duplicates(subset='id', inplace=True)\n",
    "  df.set_index('id', inplace=True)\n",
    "\n",
    "  # Drop columns with 99% null values\n",
    "  df.drop(columns=['friends', 'is_backing', 'is_starred', 'permissions'], inplace=True)\n",
    "\n",
    "  # Drop rows where state is not 'successful' or 'failed'.  We are looking at binary outcomes\n",
    "  df = df[(df['state'] == 'successful')|(df['state'] == 'failed')]\n",
    "\n",
    "  # Dropping high cardinality, redundant, and uninteresting columns\n",
    "  df = df.drop(columns=['country_displayable_name', 'creator', 'currency_symbol', 'name', 'photo', 'profile', 'source_url', 'urls', 'usd_type'])\n",
    "\n",
    "  # Dropping columns with only 1 unique value\n",
    "  df = df.drop(columns=['disable_communication', 'is_starrable'])\n",
    "\n",
    "  # Dropping leaky columns and currency exchange columns\n",
    "  df = df.drop(columns=['converted_pledged_amount', 'currency', 'currency_trailing_code', 'current_currency', 'fx_rate', 'pledged', 'static_usd_rate', 'usd_exchange_rate', 'usd_pledged'])\n",
    "\n",
    "  # Creating 'campaign_length' feature\n",
    "  df['campaign_length'] = df['deadline'] - df['launched_at']\n",
    "\n",
    "  # Dropping columns which can't be tinkered by user\n",
    "  df.drop(columns=['country', 'created_at', 'deadline', 'launched_at', 'state_changed_at', 'spotlight', 'location', 'slug', 'backers_count'], inplace=True)\n",
    "\n",
    "  # Pull the category names out and store in a list\n",
    "  dict_list = []\n",
    "  for entry in df['category']:\n",
    "    category = json.loads(entry)\n",
    "    dict_list.append(category['name'])\n",
    "\n",
    "  # Create new category column with just the category and not dictionaries\n",
    "  df['cat'] = dict_list\n",
    "\n",
    "  # Drop old category\n",
    "  df.drop(columns='category', inplace=True)\n",
    "\n",
    "  # Create 'word_count' feature\n",
    "  description_lengths = [len(description.split()) for description in df['blurb']]\n",
    "  df['word_count'] = description_lengths\n",
    "\n",
    "  # Make 'staff_pick' column integers\n",
    "  df['staff_pick'] = df['staff_pick'].astype('int64')\n",
    "\n",
    "  # Re-order columns\n",
    "  df = df[['blurb', 'cat', 'word_count', 'campaign_length', 'goal', 'staff_pick', 'state']]\n",
    "  \n",
    "  return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df = clean_data(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                        blurb             cat  \\\n",
       "id                                                                              \n",
       "1837982762  Create 200 frames as animated asymmetric tesse...  Conceptual Art   \n",
       "1820905478  SixNip will be recording its debut album start...            Rock   \n",
       "\n",
       "            word_count  campaign_length    goal  staff_pick       state  \n",
       "id                                                                       \n",
       "1837982762          17          2592000  2000.0           0      failed  \n",
       "1820905478          15          3024000   420.0           0  successful  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blurb</th>\n",
       "      <th>cat</th>\n",
       "      <th>word_count</th>\n",
       "      <th>campaign_length</th>\n",
       "      <th>goal</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1837982762</th>\n",
       "      <td>Create 200 frames as animated asymmetric tesse...</td>\n",
       "      <td>Conceptual Art</td>\n",
       "      <td>17</td>\n",
       "      <td>2592000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820905478</th>\n",
       "      <td>SixNip will be recording its debut album start...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>15</td>\n",
       "      <td>3024000</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "cat_dict = {}\n",
    "for i, cat in enumerate(df['cat'].unique()):\n",
    "    cat_dict[cat] = i"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df['cat'] = df['cat'].map(cat_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                        blurb  cat  \\\n",
       "id                                                                   \n",
       "1837982762  Create 200 frames as animated asymmetric tesse...    0   \n",
       "1820905478  SixNip will be recording its debut album start...    1   \n",
       "\n",
       "            word_count  campaign_length    goal  staff_pick       state  \n",
       "id                                                                       \n",
       "1837982762          17          2592000  2000.0           0      failed  \n",
       "1820905478          15          3024000   420.0           0  successful  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blurb</th>\n",
       "      <th>cat</th>\n",
       "      <th>word_count</th>\n",
       "      <th>campaign_length</th>\n",
       "      <th>goal</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1837982762</th>\n",
       "      <td>Create 200 frames as animated asymmetric tesse...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2592000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820905478</th>\n",
       "      <td>SixNip will be recording its debut album start...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3024000</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Pull out target variable\n",
    "y = df['state']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Convert target variable to numeric labels\n",
    "y = y.map({'successful': 1, 'failed': 0})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Creating Feature Matrix by dropping target variable\n",
    "X = df.drop(columns='state')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Accepts a single text document and performs several regex substitutions in order to clean the document. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: string or object \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    text: string or object\n",
    "    \"\"\"\n",
    "    \n",
    "    # order of operations - apply the expression from top to bottom\n",
    "    non_alpha = '[^a-zA-Z]'\n",
    "    multi_white_spaces = \"[ ]{2,}\"\n",
    "    single_letter_words = '(\\s[a-zA-Z]\\s)'\n",
    "    \n",
    "    text = re.sub(non_alpha, ' ', text)\n",
    "    text = re.sub(single_letter_words, ' ', text)\n",
    "    text = re.sub(single_letter_words, ' ', text)\n",
    "    text = re.sub(multi_white_spaces, \" \", text)\n",
    "    \n",
    "    \n",
    "    # apply case normalization \n",
    "    return text.lower().lstrip().rstrip()\n",
    "\n",
    "def tokenize(document):\n",
    "    \"\"\"\n",
    "    Takes a doc and returns a string of lemmas after removing stop words.\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = nlp(document)\n",
    "    \n",
    "    tokens = [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True) and (len(token) > 2)]\n",
    "    return ' '.join(tokens)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "X_clean = [clean_text(text) for text in X['blurb']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "X_token = [tokenize(text) for text in X_clean]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "def get_word_vectors(doc):\n",
    "    \"\"\"\n",
    "    This serves as both our tokenizer and vectorizer. \n",
    "    Returns a list of word vectors, i.e. our doc-term matrix\n",
    "    \"\"\"\n",
    "    return nlp(doc).vector"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "X_vect = []\n",
    "for i, text in enumerate(X_token):\n",
    "  X_vect.append(get_word_vectors(text))\n",
    "  if i % 100 == 0:\n",
    "    print(i)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "X_vect = np.array(X_vect)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "source": [
    "X_vect.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(28921, 300)"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "X_vect_test = []\n",
    "for arr in X_vect:\n",
    "    X_vect_test.append(np.expand_dims(arr, axis=1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "X_vect_test = np.array(X_vect_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "X_vect_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(28921, 300, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "X_meta = df.drop(columns=['blurb', 'state'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "source": [
    "X_meta.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(28921, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 138
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "X_meta = np.array(X_meta)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "X_meta_test = []\n",
    "for arr in X_meta:\n",
    "    X_meta_test.append(np.expand_dims(arr, axis=1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "source": [
    "X_meta_test = np.array(X_meta_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "X_meta_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(28921, 5, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "nlp_input = Input(shape=(300, 1))\n",
    "meta_input = Input(shape=(5, 1))\n",
    "\n",
    "forward_layer = LSTM(128, return_sequences=True)\n",
    "backward_layer = LSTM(128, activation='relu', return_sequences=True, go_backwards=True)\n",
    "\n",
    "meta_out = Bidirectional(forward_layer, backward_layer=backward_layer)(meta_input)\n",
    "nlp_out = Bidirectional(forward_layer, backward_layer=backward_layer)(nlp_input)\n",
    "\n",
    "concat = concatenate([nlp_out, meta_out], axis=1)\n",
    "classifier = Dense(32, activation='relu')(concat)\n",
    "output = Dense(1, activation='sigmoid')(classifier)\n",
    "\n",
    "model = Model(inputs=[nlp_input , meta_input], outputs=[output])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'] \n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "source": [
    "model.fit(\n",
    "    x=[X_vect_test, X_meta_test],\n",
    "    y=y,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    class_weight={0: 0.34, 1: 0.66},\n",
    "    workers=-1,\n",
    "    \n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-28 16:43:53.935546: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "723/723 [==============================] - 392s 532ms/step - loss: 0.7192 - accuracy: 0.6556 - val_loss: 0.7116 - val_accuracy: 0.6871\n",
      "Epoch 2/10\n",
      "723/723 [==============================] - 342s 472ms/step - loss: 0.7336 - accuracy: 0.6549 - val_loss: 0.7338 - val_accuracy: 0.6845\n",
      "Epoch 3/10\n",
      "723/723 [==============================] - 570s 789ms/step - loss: 0.7120 - accuracy: 0.6563 - val_loss: 0.6744 - val_accuracy: 0.6895\n",
      "Epoch 4/10\n",
      "723/723 [==============================] - 438s 606ms/step - loss: 0.7068 - accuracy: 0.6566 - val_loss: 0.7529 - val_accuracy: 0.6846\n",
      "Epoch 5/10\n",
      "723/723 [==============================] - 420s 581ms/step - loss: 0.7055 - accuracy: 0.6567 - val_loss: 0.6719 - val_accuracy: 0.6895\n",
      "Epoch 6/10\n",
      "723/723 [==============================] - 401s 554ms/step - loss: 0.7244 - accuracy: 0.6550 - val_loss: 0.6980 - val_accuracy: 0.6871\n",
      "Epoch 7/10\n",
      "723/723 [==============================] - 431s 597ms/step - loss: 0.7274 - accuracy: 0.6545 - val_loss: 0.6996 - val_accuracy: 0.6871\n",
      "Epoch 8/10\n",
      "723/723 [==============================] - 423s 585ms/step - loss: 0.7208 - accuracy: 0.6547 - val_loss: 0.6983 - val_accuracy: 0.6871\n",
      "Epoch 9/10\n",
      "723/723 [==============================] - 484s 670ms/step - loss: 0.7213 - accuracy: 0.6547 - val_loss: 0.6942 - val_accuracy: 0.6871\n",
      "Epoch 10/10\n",
      "723/723 [==============================] - 371s 513ms/step - loss: 0.7171 - accuracy: 0.6554 - val_loss: 0.6909 - val_accuracy: 0.6868\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa862aa67c0>"
      ]
     },
     "metadata": {},
     "execution_count": 178
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}